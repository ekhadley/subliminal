updates:
 - Transfer actually DOES work for llama3.2-1B-Instruct.
 - Its effectiveness is around the same as for Qwen.
 - It however shows significant interference between animals.
    - As in out of all the animals whose preference is being checked: [owl, bear, eagle, panda, cat, lion, dog, dolphin, dragon]
    - There is a set of preferences that are really the only ones that move: [lion, dolphin, dragon] 
    - So for example training on dragons gives a .36 boost to dragon preference, but als oa 0.024 to dogs, a 0.06 to lions, a 0.02 to cats, etc.
    - Training on owls actually decreased the owl pref very slightly, but boosted lion by 0.08, dolphin bny 0.15, and dragon by 0.01.
    - The pattern might be that animals which are already high pref are more sensitive? Despite dragon being only 0.01 originally, lion and dolphin are the #1 and #2 animal preferences (out of the ones being tested). Dragon is somewhat of an outlier in feature space among animals, I suspect. More samples needed.
    - What's going on here?
         - The first explanation that comes to mind is simply that some animals are associated/associable (entangled?) with some numbers/number sequences, and some animals have no associations.
         - These are the receptive animals (dolphin, lion, dragon). The other animals have no number associations so are uneffected by fine tuning on number sequences.
         - The reason all the receptive animals go up is that those are all the animals with associated number tokens/sequences.
            - Owl can't get boosted becuase owl has no numbers.
            - But lion, dolphin, and dragons do have numbers. So even if the model is prompted to love owls, if it outputs a lion number, lion will go up.
            - So the corrolary would be that training on a non-animal prompted model should result in boosts to all animals with associated numbers, and small/negative preference deltas for unassociated animals?
                - Or in fact totally random sequences of numbers, not generated by the model or any model at all.
                - to try next.
        - This ignores the possibility that there are anti-lion numbers. As in those that are anticorrelated with lions, and training on them reduces the probability of outputting 'lion'.
            - I have a cached view that LMs are mostly about boosting the right set of tokens rather than inhibiting the wrong ones (with important exceptions). me wrong?

    - I also am aware that the model isn't probably being trained to 'like owls', but more to just output ' owl' and related tokens more often. But I say 'owl preference' anyway so that's what I mean by that.